{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xq_PZhIKjqH"
   },
   "source": [
    "# **OVERFITTING AND PRUNING**\n",
    "\n",
    "The first part of the assignment will focus on overfitting and the second part will focus on pruning.\n",
    "\n",
    "Overfitting is a condition when your model fits your training data too well including the noisy labels. Therefore it fails to generalise and its performance on the test set decreases.\n",
    "\n",
    "Pruning is one method to overcome overfitting in Decision Trees. We will essentially look at one way of pruning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tq7mQaj9KyKy"
   },
   "source": [
    "## IMPORTING THE PACKAGES\n",
    "\n",
    "The important packages have been imported for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zp32CD8iKYEN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "ans = [0]*8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtfmDrFfLSG_"
   },
   "source": [
    "## LOADING THE DATASET\n",
    "\n",
    "We will load the dataset into the dataset variable. It is a diabetes dataset, a regression problem.\n",
    "\n",
    "There are 11 features (numerical). They include measurements like bmi, sugar level etc. The column names have been set as Feature1, Feature2 etc for ease.\n",
    "\n",
    "The target variable(numerical) is a quantitative measure of how much the disease has progressed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "x6AzbFhvMxA3",
    "outputId": "f206e357-e1a2-4f3b-e40d-e502fa5e16cc"
   },
   "outputs": [],
   "source": [
    "# LOADING THE DATASET USING SKLEARN.\n",
    "# THE CODE HAS BEEN WRITTEN FOR YOU. DO NOT MAKE ANY CHANGES.\n",
    "\n",
    "data, label = load_diabetes(return_X_y = True)                    #loading the dataset\n",
    "cols = [\"Feature\"+str(i) for i in range(1, 11)] \n",
    "dataset = pd.DataFrame(np.concatenate((data, label.reshape(-1, 1)), axis = 1), columns = cols + [\"Target\"])\n",
    "print(\"Shape of Dataset : \", dataset.shape, \"\\n\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olzQ3DBgPMBo"
   },
   "source": [
    "## DIVIDING THE DATASET INTO TRAIN AND TEST SET\n",
    "\n",
    "You need to divide the dataset into train and test set using sklearn's train_test_split(x, y, random_state = 15, test_size = x) function. x is the fraction of examples to be alloted to the test set.\n",
    "\n",
    "You need to divide the dataset in 8:2 ratio (train:test size).\n",
    "\n",
    "**NOTE**: Remember to keep random_state = 15 (produces consistent results for evaluation purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6LurLByNV5V"
   },
   "outputs": [],
   "source": [
    "# DIVIDE THE DATASET INTO TRAIN AND TEST SET\n",
    "\n",
    "# START YOUR CODE HERE:\n",
    "\n",
    "X = dataset.iloc[:, [*range(len(dataset.columns)-1)]]\n",
    "y = dataset.iloc[:, [-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOWZaL8sRpAp"
   },
   "source": [
    "## **QUESTIONS**\n",
    "## **OVERFITTING**\n",
    "\n",
    "It is when your model is too complex and fits the noisy parts of your training data. Therefore it fails to generalize and achieves a bad result on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpzH7kRlSOri"
   },
   "source": [
    "### **QUESTION 1**: Fit a Decision Tree Classifier with max_depth = 1 on the training dataset. Assign the train set mean squared error to ans[0] and the test set mean squared error to ans[1]. (1 mark)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihLlfBv4NTjL"
   },
   "outputs": [],
   "source": [
    "# SOME PART OF THE CODE HAS BEEN WRITTEN FOR YOU\n",
    "\n",
    "dt1 = DecisionTreeRegressor(max_depth = 1, random_state = 20)    # The decision tree model you need to use. Don't change parameters.\n",
    "\n",
    "# START YOUR CODE HERE:\n",
    "\n",
    "dt1 = dt1.fit(X_train, y_train)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, dt1.predict(X_train))\n",
    "mse_test = mean_squared_error(y_test, dt1.predict(X_test))\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-ZHWlVsUUtD"
   },
   "outputs": [],
   "source": [
    "# SUBSTITUTE YOUR ANSWER IN PLACE OF None\n",
    "\n",
    "ans[0] = mse_train\n",
    "ans[1] = mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQETIzFbYdVg"
   },
   "source": [
    "### **QUESTION 2**: Fit a Decision Tree Classifier with max_depth = 2 on the training dataset. Assign the train set mean squared error to ans[2] and the test set mean squared error to ans[3]. (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84XPnBgaVfWN"
   },
   "outputs": [],
   "source": [
    "# SOME PART OF THE CODE HAS BEEN WRITTEN FOR YOU\n",
    "\n",
    "dt4 = DecisionTreeRegressor(max_depth = 2, random_state = 20)        # The decision tree model you need to use. Don't change parameters.\n",
    "\n",
    "# START YOUR CODE HERE:\n",
    "\n",
    "dt4 = dt4.fit(X_train, y_train)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, dt4.predict(X_train))\n",
    "mse_test = mean_squared_error(y_test, dt4.predict(X_test))\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLy0-ZcVYlXc"
   },
   "outputs": [],
   "source": [
    "# SUBSTITUTE YOUR ANSWER IN PLACE OF None\n",
    "\n",
    "ans[2] = mse_train\n",
    "ans[3] = mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KDYxndBZLgt"
   },
   "source": [
    "Did the accuracy for test set go down?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLBr_PMuY6g_"
   },
   "source": [
    "### **QUESTION 3**: Fit a Decision Tree Classifier with max_depth = 5 on the training dataset. Assign the train set accuracy to ans[4] and the test set accuracy to ans[5]. (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1Duo-miXzA3"
   },
   "outputs": [],
   "source": [
    "# SOME PART OF THE CODE HAS BEEN WRITTEN FOR YOU\n",
    "\n",
    "dt5 = DecisionTreeRegressor( max_depth = 5, random_state = 20)      # The decision tree that you need to use. Don't change parameters.\n",
    "\n",
    "# START YOUR CODE HERE:\n",
    "\n",
    "dt5 = dt5.fit(X_train, y_train)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, dt5.predict(X_train))\n",
    "mse_test = mean_squared_error(y_test, dt5.predict(X_test))\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_2CkxB7X7SM"
   },
   "outputs": [],
   "source": [
    "# SUBSTITUTE YOUR ANSWER IN PLACE OF None\n",
    "\n",
    "ans[4] = mse_train\n",
    "ans[5] = mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neSLl4qBZQCz"
   },
   "source": [
    "Did the accuracy of the test set go down again? If not then why? Is overfitting the reason?\n",
    "\n",
    "### **PLOTTING TRAIN AND TEST ACCURACY VS DEPTH OF TREES**\n",
    "\n",
    "Let's try to plot the train and test accuracy vs max_depth.\n",
    "Some part of the code has been written for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUDfDc8cOzMM"
   },
   "source": [
    "### **QUESTION 4**: Fit a Decision Tree Classifier with max_depth = d where d varies from 1-6 (both inclusive) on the training dataset. Assign the depth for which the test mean squared error is least, to ans[6]. (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBJQOaaYaSnm"
   },
   "outputs": [],
   "source": [
    "# SOME OF THE CODE HAS BEEN WRITTEN FOR YOU\n",
    "\n",
    "depth = []                               # List containing depth of decision tree.\n",
    "train_mse = []                           # Train accuracy of corresponding tree.\n",
    "test_mse = []                            # Test accuracy of corresponding tree.\n",
    "\n",
    "# Dont forget to set random_state = 10 for your decision tree model.\n",
    "random_state = 10\n",
    "depth = [*range(1, 7)]\n",
    "\n",
    "# START YOUR CODE HERE:\n",
    "\n",
    "for d in depth:\n",
    "  dt = DecisionTreeRegressor(max_depth= d, random_state= random_state)\n",
    "  dt = dt.fit(X_train, y_train)\n",
    "  mse_train = mean_squared_error(y_train, dt.predict(X_train))\n",
    "  mse_test = mean_squared_error(y_test, dt.predict(X_test))\n",
    "  train_mse.append(mse_train)\n",
    "  test_mse.append(mse_test)\n",
    "\n",
    "# END YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xg8YUGWJPbvR"
   },
   "outputs": [],
   "source": [
    "# SUBSTITUTE YOUR ANSWER IN PLACE OF None\n",
    "\n",
    "ans[6] = depth[test_mse.index(min(test_mse))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7ZVrzRAg4wN"
   },
   "source": [
    "### PLOTTING MEAN SQUARED ERROR VS THE DEPTH OF THE TREE\n",
    "\n",
    "You can try to plot the train mean squared error and the test mean squared error vs the depth of the tree for gaining a better insight.\n",
    "\n",
    "Some part of the matplotlib code has been written for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "hTSgVE2Fg0Ng",
    "outputId": "2c921f20-69b7-4711-f09a-5f187047b3d7"
   },
   "outputs": [],
   "source": [
    "plt.plot(depth, train_mse, c = \"r\", label = \"Train Mse\")\n",
    "plt.plot(depth, test_mse, c = \"g\", label = \"Test Mse\")\n",
    "plt.legend()\n",
    "plt.xlim(1)\n",
    "plt.xticks(ticks = [i for i in range(1, 7)])\n",
    "plt.title(\"Mean Squared Error vs Max Depth\")\n",
    "plt.xlabel(\"Max depth of the Decision Tree\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3K2FbfaUhWWP"
   },
   "source": [
    "## **PRUNING**\n",
    "\n",
    "We will look at one way to prune a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4mfNIRURc4A"
   },
   "source": [
    "## USING SKLEARN'S INBUILT PRUNING ALGORITHM\n",
    "We will use a inbuilt parameter in the sklearn Decision Tree Regressor model called ccp_alpha to prune the Decision Trees formed.\n",
    "\n",
    "**Minimal Cost Complexity Pruning**: One of the types of pruning in Decision Trees. \n",
    "\n",
    "It utilises a complexity parameter **alpha** (alpha > 0). It is used to define a cost complexity measure of a tree as:-\n",
    "\n",
    "$R_{alpha}(T) = R(T) + alpha*|T|$ where |T| are the number of terminal nodes in the tree, R(T) is the misclassification rate of the terminal nodes (a mean squared error type of quantity for regression and accuracy type of quantity for classification).\n",
    "\n",
    "R(T) as you must have noticed always favours bigger trees as their misclassification rate would be always lower (remember we are talking about training set misclassification rate). So to penalise the bigger ones alpha*|T| term is added as it would favour a smaller tree.\n",
    "\n",
    "alpha is what we call a hyperparameter. We need to find the best values of alpha to decrease the test set mean squared error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRW7nb5pR1Qb"
   },
   "source": [
    "### **QUESTION 5**: For which values of alpha (a) 10 (b) 50 (c) 100 (d) 200 is the test mean squared error the lowest? (We will use a tree with max_depth = 4). Assign your answer (the value of alpha and not the option) to ans[7]. (3 marks)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThCkE11IcOSs"
   },
   "outputs": [],
   "source": [
    "# SOME OF THE MATPLOTLIB CODE HAS BEEN WRITTEN FOR YOU\n",
    "\n",
    "train_mse = []                           # Train accuracy of corresponding tree.\n",
    "test_mse = []                            # Test accuracy of corresponding tree.\n",
    "alphas = [10, 50, 100, 200]\n",
    "\n",
    "# KEEP ALL PARAMETERS OTHER THAN ccp_alpha the same. REPLACE None WITH THE GIVEN VALUES OF ALPHA BEFORE FITTING ON THE TRAIN SET.\n",
    "dt_temp = DecisionTreeRegressor(max_depth = 4, random_state = 10, ccp_alpha = None)\n",
    "\n",
    "# START YOUR CODE HERE\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "  dt_temp = DecisionTreeRegressor(max_depth = 4, random_state = 10, ccp_alpha = alpha)\n",
    "  dt_temp = dt_temp.fit(X_train, y_train)\n",
    "  mse_train = mean_squared_error(y_train, dt_temp.predict(X_train))\n",
    "  mse_test = mean_squared_error(y_test, dt_temp.predict(X_test))\n",
    "  train_mse.append(mse_train)\n",
    "  test_mse.append(mse_test)\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMZ6A42BFHZz"
   },
   "outputs": [],
   "source": [
    "# SUBSTITUTE YOUR ANSWER IN PLACE OF None\n",
    "\n",
    "ans[7] = alphas[test_mse.index(min(test_mse))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJDaRfrJeWaF"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "ans = [str(item) for item in ans]\n",
    "\n",
    "filename = \"group15_mohanlals1211973@gmail.com_Harsh_Sharma_Issues_Classification\"\n",
    "\n",
    "# Eg if your name is Saurav Joshi and group id is 0, filename becomes\n",
    "# filename = group0_Saurav_Joshi_Issues_Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8ltfHSHNk8b"
   },
   "source": [
    "## Do not change anything below!!\n",
    "- Make sure you have changed the above variable \"filename\" with the correct value. Do not change anything below!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "zj63no1wc7jY",
    "outputId": "f1bb787a-7a5b-4b8e-98dc-aea304c344fe"
   },
   "outputs": [],
   "source": [
    "from importlib import import_module\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "findScore = import_module('findScore')\n",
    "response = findScore.main(ans)\n",
    "response['details'] = filename\n",
    "with open(f'evaluation_{filename}.json', 'w') as outfile:\n",
    "    json.dump(response, outfile)\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "group0_Saurav_Joshi_Issues_Classification (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
