{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cB-uAPFjwTac"
   },
   "source": [
    "# ***` Logistic Regression `***\n",
    "\n",
    "***` Import the Iris data which discusses about three species of flowers namely \"Setosa\",\"Verisicolor\" and \"Virginica\" Your task is to build a logistic regression model to distinguish between two  of these speicies using features like \"Sepal Length\", \"Sepal Width\", \"Petal Length\" and \"Petal Width\"`***\n",
    "\n",
    "`1)Write a sigmoid function and visualize the sigmoid function,by considering x in the range of (-10,10).`\n",
    "\n",
    "`2)Plot impact of logloss for single forecasts (You can import log_loss from sklearn.metrics). Make predictions as 0 to 1 in 0.01 increments. (For example,yhat = [x*0.01 for x in range(0, 101)]).Evaluate predictions for a 0 true value.Plot a graph between y_hat and log_loss`\n",
    "\n",
    "`3)Find the difference between minimum log loss for label 0 and label 1 [1.5 marks]`\n",
    "\n",
    "`3)Import the Iris Data, and visualize the data to an idea about it.`\n",
    "\n",
    "`4)Convert the char labels to numerical as logistic regression takes only 0's and 1's and then create new array of numerical labels.After following the procedure as mentioned in the comments , find the difference between means of sepal length of speices \"Setosa\"(label 0) and \"Versicolor\"(label 1).[1 marks]`\n",
    "\n",
    "`5)Split the data in X,y and convert them into arrays`\n",
    "\n",
    "`6)Use sklearn to split the data (**Important** Consider random_state=42 and test_size=0.2)and perform Logistic Regression`\n",
    "\n",
    "`7)Find the weights and bias and save it in a list[5 marks]`\n",
    "\n",
    "`8)Make a prediction on the test data.Find the accuracy of the prediction.[1 marks]`\n",
    "\n",
    "`9)Also predict the species of the flower whose sepal length=4.9cm\tsepal width=4cm\tpetal length=1.2cm\tpetal width=0.4cm and return the Species of the data.[1.5 marks]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mm-qMhGZ4fA4"
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "# import important libraries library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "%matplotlib inline\n",
    "ans = [0]*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXXUExSDCjnl"
   },
   "source": [
    "# ***`Importing and Visualizing Data`***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfmHr1_3463o"
   },
   "outputs": [],
   "source": [
    "#Sigmoid Function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "TJ7YufS579-a",
    "outputId": "3b37fb61-b606-4763-d690-12ee90a1d5ca"
   },
   "outputs": [],
   "source": [
    "#Visualize sigmoid function\n",
    "#Create an array of x_val with values between -10 and 10 \n",
    "x_val = np.array([*range(-1000, 1001)])/100\n",
    "#Find y_val, by using sigmoid function\n",
    "y_val = sigmoid(x_val)\n",
    "#Plot x_val,y_val and label the graph\n",
    "plt.plot(x_val, y_val, label='y = sigmoid(x)', c='maroon')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y = sigmoid(x)')\n",
    "plt.legend()\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "Ud5MNVfP5aay",
    "outputId": "63808392-5073-4314-c6a8-73aeeb597c60"
   },
   "outputs": [],
   "source": [
    "# Plot impact of logloss for single forecasts\n",
    "from sklearn.metrics import log_loss\n",
    "# predictions as 0 to 1 in 0.01 increments\n",
    "y_hat = [x*0.01 for x in range(0, 101)]\n",
    "# evaluate predictions for a 0 true value\n",
    "l0 = [log_loss([0], [x], labels= [0, 1]) for x in y_hat]\n",
    "# evaluate predictions for a 1 true value\n",
    "l1 = [log_loss([1], [x], labels= [0, 1]) for x in y_hat]\n",
    "# plot input to loss\n",
    "plt.plot(y_hat, l0, label='log_loss | true label = 0', c= 'maroon')\n",
    "plt.plot(y_hat, l1, label='log_loss | true label = 1', c= 'violet')\n",
    "plt.xlabel('y_hat')\n",
    "plt.ylabel('log_loss')\n",
    "plt.legend()\n",
    "plt.title('Log_Loss v/s y_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sru3xE4T5m4S"
   },
   "outputs": [],
   "source": [
    "#Find the difference between minimum log loss for label 0 and label 1 \n",
    "ans[0]= min(l0) - min(l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MVaovvQDbkI"
   },
   "source": [
    "# ***`Processing the Data`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Y-Rs5FsyvwO"
   },
   "outputs": [],
   "source": [
    "#Import the dataset of iris from datasets.load_iris()\n",
    "raw_data = datasets.load_iris()\n",
    "data = pd.DataFrame(data=raw_data.data, columns=raw_data.feature_names)\n",
    "data['Species'] = raw_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "5eAYcnHNy2y_",
    "outputId": "9f2f15da-5da6-4919-ca7b-de2825cd7f6f"
   },
   "outputs": [],
   "source": [
    "#Look into the top 5 rows of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "A12q7ycCy5v9",
    "outputId": "aa4801e1-631e-40d4-ffb9-1afe3bc88efb"
   },
   "outputs": [],
   "source": [
    "#Visualize  the data using seaborn pairplot\n",
    "sns.pairplot(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxxsJjf65p6U"
   },
   "outputs": [],
   "source": [
    "# Convert char labels into numerical \n",
    "#import LabelEncoder which returns array of encoded labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "# Create new array of numerical labels\n",
    "new_labels = labelencoder.fit_transform(data['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzctMiRt5xur"
   },
   "outputs": [],
   "source": [
    "# Drop old labels(char) data \n",
    "data.drop(columns=['Species'], axis=1, inplace=True)\n",
    "# Substitute new labels(numerical) into data\n",
    "data['labels'] = new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EVpJnTw-xYf"
   },
   "outputs": [],
   "source": [
    "# Logistic regression only takes the data which has labels 0 and 1, so consider only data['labels']<2\n",
    "# Considering Iris-setosa as \"0\" and Iris-versicolor as \"1\"\n",
    "data = data[data['labels']<2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ay065RGxOFPU"
   },
   "outputs": [],
   "source": [
    "#Find the difference between means of sepal length of speices \"Setosa\"(label 0) and \"Versicolor\"(label 1)\n",
    "ans[1]= data[data['labels']==0].describe().loc['mean', 'sepal length (cm)'] - data[data['labels']==1].describe().loc['mean', 'sepal length (cm)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-b3xRiIDkr1"
   },
   "source": [
    "# ***`Obtaining Weight Values`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRo8pY80_w5L"
   },
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "X = data.iloc[:, [*range(len(data.columns)-1)]]\n",
    "y = data.iloc[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 940
    },
    "id": "kEi8Pqsr_9yo",
    "outputId": "5e2c2fc5-3850-4b99-f1cc-1ff2beb67970"
   },
   "outputs": [],
   "source": [
    "# Visualize X,y\n",
    "print(sns.pairplot(X))\n",
    "print(sns.pairplot(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8E3fZvS0AC1l"
   },
   "outputs": [],
   "source": [
    "# Convert X,y into arrays\n",
    "X_arr = X.to_numpy()\n",
    "y_arr = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtyRrzy7ALXe"
   },
   "outputs": [],
   "source": [
    "#Using sklearn to split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Take the test size as 0.2 and random_state as 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ixwU-Il2xnY"
   },
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries for Logistic Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Building our model\n",
    "clf = LogisticRegression().fit(X_train, y_train.reshape(-1, ))\n",
    "#Finding the parameter and bias\n",
    "parameters = clf.coef_\n",
    "bias = clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTwvokIegTet",
    "outputId": "dbf4a059-9cdc-4d29-f383-76e47ab0c02d"
   },
   "outputs": [],
   "source": [
    "#Printing the parameters and bias\n",
    "print('parameters: ', parameters[0])\n",
    "print('bias: ', bias.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L80X7QCKGd1W"
   },
   "outputs": [],
   "source": [
    "#Save parameters and bias [w1,w2,w3,w4,b] as one vector \n",
    "#i.e if the answer should be in a 1 dimensional list\n",
    "ans[2]= parameters[0].tolist() + bias.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WT2GgltTHHr8"
   },
   "outputs": [],
   "source": [
    "#Predicitng on our test data\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jvas_HlXULz"
   },
   "outputs": [],
   "source": [
    "#Finding the accuracy\n",
    "ans[3]= metrics.accuracy_score(y_test.reshape(-1, ), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUSE7DJyVpTE"
   },
   "outputs": [],
   "source": [
    "#Predict for the input [4.9,4,1.2,0.4] , save the answer ans[4] \"Setosa\" or \"Versicolor\"\n",
    "pred = clf.predict(np.array([4.9,4,1.2,0.4]).reshape(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wl7bv6bq2MwR"
   },
   "outputs": [],
   "source": [
    "#The class of the input \n",
    "ans[4]= 'Setosa' if pred.item() == 0 else 'Versicolor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fup39iBFhiv"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "ans = [str(item) for item in ans]\n",
    "\n",
    "filename = \"group15_mohanlals1211973@gmail.com_Harsh_Sharma_LogisticRegression\"\n",
    "\n",
    "# Eg if your name is Saurav Joshi and email id is sauravjoshi123@gmail.com, filename becomes\n",
    "# filename = sauravjoshi123@gmail.com_Saurav_Joshi_LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzu20Sk9Fhiw"
   },
   "source": [
    "## Do not change anything below!!\n",
    "- Make sure you have changed the above variable \"filename\" with the correct value. Do not change anything below!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "L1b4c3rkFj_w",
    "outputId": "61a6e37a-ad6b-4192-9916-e89cf1bb7fdf"
   },
   "outputs": [],
   "source": [
    "from importlib import import_module\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "findScore = import_module('findScore')\n",
    "response = findScore.main(ans)\n",
    "response['details'] = filename\n",
    "with open(f'evaluation_{filename}.json', 'w') as outfile:\n",
    "    json.dump(response, outfile)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFBOXitWPfK8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "group0_Saurav_Joshi_LogisticRegression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
